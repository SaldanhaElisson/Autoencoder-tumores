ğŸ§  Brain Tumor Detection Using CNN

ğŸŒ Overview

Este projeto tem como objetivo detectar tumores cerebrais usando Redes Neurais Convolucionais (CNNs). O conjunto de dados Ã© composto por imagens mÃ©dicas, e o modelo Ã© treinado para classificar diferentes tipos de tumores de forma eficiente.

ğŸ“Š Dataset

- Total de Amostras: 9792

- Dados de Treinamento: 90% (8812 imagens)

- Dados de Teste: 10% (980 imagens)

- Tipo de Imagem: Scans de ressonÃ¢ncia magnÃ©tica (MRI) mÃ©dicas

âš™ï¸ Methodology

A metodologia consiste em trÃªs fases principais: prÃ©-processamento dos dados, seleÃ§Ã£o do modelo e treinamento & avaliaÃ§Ã£o. Durante o prÃ©-processamento, as imagens sÃ£o redimensionadas, normalizadas e aumentadas quando necessÃ¡rio para melhorar a generalizaÃ§Ã£o do modelo. A arquitetura escolhida Ã© uma CNN 2D com mÃºltiplas camadas convolucionais, seguidas por camadas totalmente conectadas para classificar as imagens em diferentes tipos de tumor. O treinamento do modelo utiliza o otimizador Adam, e o desempenho Ã© avaliado atravÃ©s de mÃ©tricas como acurÃ¡cia, precisÃ£o, recall e F1-score.

ğŸ—ï¸ Architecture of 2D CNN

O modelo recebe imagens em tons de cinza de 80x80 como entrada. Ele Ã© estruturado em oito camadas convolucionais: as duas primeiras utilizam 64 filtros, as duas seguintes 32 filtros, depois duas camadas com 16 filtros, e as Ãºltimas duas com 8 filtros. Cada camada convolucional emprega um kernel de 2x2, e camadas de pooling sÃ£o inseridas estrategicamente apÃ³s algumas camadas convolucionais. Para melhorar a extraÃ§Ã£o de caracterÃ­sticas e reduzir o overfitting, a normalizaÃ§Ã£o em lote (batch normalization) Ã© aplicada em toda a arquitetura, e uma taxa de dropout de 0.1 Ã© definida apÃ³s as camadas de pooling e densas. A rede culmina em uma camada totalmente conectada com 1024 neurÃ´nios, seguida por uma camada softmax que classifica as imagens em quatro categorias. O modelo Ã© treinado usando o otimizador Adam, com diferentes taxas de aprendizado testadas (0.01, 0.001 e 0.0001), e a funÃ§Ã£o de perda utilizada Ã© a entropia cruzada categÃ³rica. O treinamento ocorre por 100 Ã©pocas com um tamanho de lote de 16.

ğŸ“ˆ Model Training

ğŸ› ï¸ Otimizador: Adam

ğŸ¯ FunÃ§Ã£o de Perda: Entropia Cruzada CategÃ³rica

â³ Tempo de Treinamento por Ã‰poca: ~7s

ğŸ§® ParÃ¢metros TreinÃ¡veis Totais: 243,924

ğŸ’» Hardware Utilizado: NVIDIA RTX 4060

ğŸ† Results

ğŸ“Š AcurÃ¡cia: O modelo atingiu alta precisÃ£o na classificaÃ§Ã£o

ğŸ“‰ ReduÃ§Ã£o da Perda: A perda de treinamento diminuiu consistentemente ao longo das Ã©pocas

ğŸ—ï¸ Autoencoder Architecture

O Autoencoder foi implementado para prÃ©-processamento e extraÃ§Ã£o de caracterÃ­sticas antes do modelo CNN. Ele consiste em camadas convolucionais encoder-decoder, com uma camada de cÃ³digo comprimido para representaÃ§Ã£o eficiente. O treinamento foi realizado utilizando o otimizador Adam e a funÃ§Ã£o de perda MSE (Mean Squared Error), garantindo que as imagens reconstruÃ­das fossem prÃ³ximas Ã s originais.

ğŸ’» Hardware Utilizado: NVIDIA RTX 3060

ğŸ‘¨â€ğŸ’» Contributors

- [JoÃ£o Pedro Lima](https://github.com/JpLimags)  
- [Elisson Saldanha](https://github.com/SaldanhaElisson)



